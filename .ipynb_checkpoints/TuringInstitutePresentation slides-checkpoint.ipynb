{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "* My experience: mixture of implementing bespoke reconstruction algorithms for specific purposes & experimental physics.\n",
    "\n",
    "* More recently, I have begun working with more traditional ML algorithms.\n",
    "\n",
    "* One area I have experience in is classification (classifying objects in a metal detector as threat or benign).\n",
    "\n",
    "* I have a dataset of [Fix My Street](https://www.fixmystreet.com/) reports - an online portal to report local problems.\n",
    "\n",
    "* My presentation will be on document classification of this dataset using **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes\n",
    "Why Naive Bayes?\n",
    "\n",
    "* It works well without a large amount of training data\n",
    "\n",
    "* Computationally efficient & scaleable\n",
    "\n",
    "* Can be easily updated with new data\n",
    "\n",
    "* Tends to work well despite the independence assumption\n",
    "\n",
    "* Model is interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes Theorem\n",
    "Naive Bayes relies on Bayes' Theorem:\n",
    "\n",
    "$$p(y|x) = \\frac{p(y)p(x|y)}{p(x)},$$\n",
    "\n",
    "assuming $p(x) \\neq 0$. Or, in other words\n",
    "\n",
    "$$p(\\text{event}|\\text{evidence}) = \\frac{\\text{prior} \\times \\text{likelihood}}{p(\\text{evidence})}.$$\n",
    "\n",
    "In classification problems we are given data $x$ and we want to assign it to a class $c_{k} \\in C$. To do this we can calculate and find the class that maximises\n",
    "\n",
    "$$p(c_{k}|x) = \\frac{p(c_{k})p(x|c_{k})}{p(x)},$$\n",
    "\n",
    "where $x = (x_{1},\\dots,x_{n})$ are our features - in this case words in a report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Method\n",
    "\n",
    "The numberator is equivalent to the joint probability distribution, written $p(x_{1},\\dots,x_{n},c_{k})$ which can be expanded using the chain rule of probabilities\n",
    "\\begin{align}\n",
    "p(x_{1},\\dots,x_{n},c_{k}) &= p(x_{1},\\dots,x_{n}|c_{k})(x_{2},\\dots,x_{n},c_{k}), \\\\\n",
    " &= p(x_{1},\\dots,x_{n}|c_{k})(x_{2},\\dots,x_{n}|c_{k})\\dots p(x_{n}|c_{k})p(c_{k}),\n",
    "\\end{align}\n",
    "If we assume **all of the features are independent**, then we have\n",
    "$$\n",
    "p(x_{1},\\dots,x_{n},c_{k}) = p(c_{k})\\prod_{i} p(x_{i}|c_{k}),\n",
    "$$\n",
    "$$p(c_{k}|x) = \\frac{p(c_{k})\\prod_{i} p(x_{i}|c_{k})}{p(x)},$$\n",
    "and our classification rule is\n",
    "$$\n",
    "\\hat{y} = \\text{argmax}_{k} p(c_{k})\\prod_{i} p(x_{i}|c_{k}).\n",
    "$$\n",
    "To avoid numerical problems when $p(x_{i}|c_{k})$ is very small, so take logs\n",
    "$$\n",
    "\\hat{y} = \\text{argmax}_{k} \\log(p(c_{k})) + \\sum_{i} \\log(p(x_{i}|c_{k})).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Event Models - The Distribution of $p(x_{i}|c_{k})$\n",
    "\n",
    "* The prior $p(c_{k})$ can be calculated assuming either equiprobable classes or estimated using the training set. \n",
    "* We have to assume a distribution for the features $p(x_{i}|c_{k})$ :\n",
    "    * Continous features - Gaussian Naive Bayes $p(x_{i}|c_{k}) = \\frac{1}{\\sqrt{2\\pi \\sigma_{k}^{2}}}\\exp{\\left(-\\frac{\\left(x_{i} - \\mu_{k}\\right)^{2}}{2 \\sigma_{k}^{2}}\\right)}$. $\\sigma_{k},\\mu_{k}$ are the mean & sd of $x_{i}$ in class $c_{k}$.\n",
    "    * Discrete features - Bernouilli Naive Bayes $p(x|c_{k}) = \\prod_{i}\\theta_{ik}^{x_{i}}\\left(1 - \\theta_{ik}\\right)^{\\left(1 - x_{i}\\right)}$. $\\theta_{ik}$ is the probability of class $c_{k}$ generating $x_{i}$. This assumes a binary model for the features.\n",
    "    * Discrete features - Multinomial Naive Bayes $p(x|c_{k}) \\propto \\prod_{i} \\theta_{ik}^{x_{i}}$. The distribution is parameterised by multinomials $\\theta_{k} = (\\theta_{1k},\\dots,\\theta_{nk})$, where $\\theta_{ik}$ is the probability of feature $i$ occuring in a sample belonging to class $c_{k}$.\n",
    "* Bernouilli & Multinomial Naive Bayes are popular for document classification. The feature matrix consists of word occurence (Bernouilli), word frequencies (Multinomial), or term frequency-inverse term document frequency (tf-idf).\n",
    "\n",
    "* Use smoothing to ensure there are no probability values $\\theta_{ik} = 1$ or $0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes for Document Classification - Outline\n",
    "* Obtain a set of labelled documents.\n",
    "\n",
    "* Generate the feature matrix $X$, either binary term occurence, document term matrix, or tf-idf.\n",
    "\n",
    "* Calculate the values of $\\theta_{ik}$ and the conditional probability $p(x_{i}|c_{k})$.\n",
    "\n",
    "* Calculate the prior probability $p(c_{k}$.\n",
    "\n",
    "* Classify new documents using $\\hat{y} = \\text{argmax}_{k} \\log(p(c_{k})) + \\sum_{i} \\log(p(x_{i}|c_{k})):$\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} &= \\text{argmax}_{k} \\log(p(c_{k})) + \\sum_{i} x_{i}\\log(\\theta_{ik})+ \\sum_{i} (1-x_{i})\\log(1-\\theta_{ik}).\\quad \\text{(Bernouilli)} \\\\\n",
    "\\hat{y} &= \\text{argmax}_{k} \\log(p(c_{k})) + \\sum_{i} x_{i}\\log(\\theta_{ik}).\\quad \\text{(Multinomial)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes Example in Julia - Fix My Street Data\n",
    "* Fix my street data contains reports of problems submitted by members of the public.\n",
    "* Reports have been pre-classified as one of: \"Car Parking\",\"Potholes\",\"Pavements/footpaths\",\"Flytipping\",\"Parks & Green Spaces\".\n",
    "* An example is: \n",
    ">Every weekday, especially between the hours of 7.30-8.30am a succession of vans completely obstruct the pavement while loading or unloading. Despite myself and other members of the public registering our concerns and pointing out the obvious danger to the public, the drivers continue this practice regardless of the very real threat to the public. We have witnessed several occasions where there have been very close misses and we feel it is only a matter of time before somebody is killed or seriously injured here. We also feel it is the councils responsibility to act now before a serious accident occurs, we have seen some (limited) parking regulation in the area but it is ineffective and does not appear to operate at all during the early morning periods when this problem is most dangerous\n",
    "\n",
    ">Label: Car Parking\n",
    "\n",
    "* I have recently started to learn Julia, which I will use for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5×2 DataFrame\n",
      "│ Row │ Key                  │ Count │\n",
      "│     │ \u001b[90mString\u001b[39m               │ \u001b[90mInt64\u001b[39m │\n",
      "├─────┼──────────────────────┼───────┤\n",
      "│ 1   │ Car Parking          │ 679   │\n",
      "│ 2   │ Potholes             │ 606   │\n",
      "│ 3   │ Pavements/footpaths  │ 500   │\n",
      "│ 4   │ Flytipping           │ 425   │\n",
      "│ 5   │ Parks & Green Spaces │ 236   │\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, Queryverse,TextAnalysis\n",
    "csv_name = \"FMS.csv\";\n",
    "# Load in the data\n",
    "df = CSV.read(csv_name);\n",
    "# Print a frequency table of the classes\n",
    "println(df |>\n",
    "    @groupby(_.category_coded) |>\n",
    "    @map({Key=key(_), Count=length(_)}) |> @orderby_descending(_.Count)|>\n",
    "    DataFrame)\n",
    "# Get the unique labels\n",
    "Classes = unique(df[!,:category_coded]);\n",
    "# Convert the report description to a String Document to build the Document Term Matrices.\n",
    "df = df |> @mutate(description = StringDocument(_.description)) |> DataFrame;\n",
    "# Grab the report descriptions and generate a corpus\n",
    "desc = deepcopy(df[!,:description]);\n",
    "crps = Corpus(desc);\n",
    "# Remve all of the words that we're not interested in.\n",
    "remove_corrupt_utf8!(crps);\n",
    "remove_case!(crps);\n",
    "remove_words!(crps,[\"amp\",\"quot\"]);\n",
    "prepare!(crps,strip_articles | strip_numbers | strip_non_letters | strip_stopwords | strip_pronouns | strip_frequent_terms | strip_definite_articles);\n",
    "# Generate the lexicon\n",
    "update_lexicon!(crps);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
